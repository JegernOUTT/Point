{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "import requests\n",
    "\n",
    "from data.models import Filial, Organization\n",
    "from doublegis_api.api import Api2Gis\n",
    "\n",
    "\n",
    "def modded_request(session, allowed_errors, **kwargs):\n",
    "    while True:\n",
    "        try:\n",
    "            r = session.get(**kwargs, timeout=3)\n",
    "            if r.status_code in allowed_errors:\n",
    "                return r\n",
    "            else:\n",
    "                print('Error in request: {0}'.format('Status code == ' + r.status_code),\n",
    "                      file=sys.stderr)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            # print('Error in request: {0}'.format(e), file=sys.stderr)\n",
    "            continue\n",
    "            \n",
    "\n",
    "def update_filials_dates(ids, filials_ids, organizations_ids, verbose=False):\n",
    "    new_filials = []\n",
    "    new_organizations = []\n",
    "    \n",
    "    session = requests.Session()\n",
    "    for i in ids:\n",
    "        r = modded_request(session=session,\n",
    "                           allowed_errors={200, 410, 404},\n",
    "                           url='https://2gis.ru/spb/firm/{0}'.format(i))\n",
    "\n",
    "        try:\n",
    "            if r.status_code == 410:\n",
    "                data = r.text.split('<script type=\"text/javascript\">')[1]\\\n",
    "                             .split('</script>')[0]\\\n",
    "                             .split('stat[pr]\\\\\":10}]\":')[1]\n",
    "                data = data[:data.find(',null,null]') + len(',null,null]')]\n",
    "                company = json.loads(data)[0]['data']\n",
    "                \n",
    "                if 'region_id' not in company.keys() \\\n",
    "                        or int(company['region_id']) != 38:\n",
    "                    continue\n",
    "                \n",
    "                if int(company['id'].split('_')[0]) in filials_ids:\n",
    "                    continue\n",
    "    \n",
    "                f = Filial()\n",
    "                f.doublegis_id = int(company['id'].split('_')[0])\n",
    "                f.organization_id = int(company['org']['id'])\n",
    "                f.building_id = int(company['address']['building_id'])\n",
    "                f.street_name = company['address']['components'][0]['street']\n",
    "                f.house = company['address']['components'][0]['number']\n",
    "                f.address_synonyms.append(company['address_name'])\n",
    "                f.longitude = float(company['point']['lon'])\n",
    "                f.latitude = float(company['point']['lat'])\n",
    "                f.created_at_json['2gis_appear_at'] = company['dates']['created_at'] if 'created_at' in company[\n",
    "                    'dates'].keys() else ''\n",
    "                f.updated_at_json['2gis_updated_at'] = company['dates']['updated_at'] if 'updated_at' in company[\n",
    "                    'dates'].keys() else ''\n",
    "                f.closed_at_json['2gis_removed_at'] = company['dates']['removed_at'] if 'removed_at' in company[\n",
    "                    'dates'].keys() else ''\n",
    "\n",
    "                filials_ids.append(f.doublegis_id)\n",
    "                new_filials.append(f)\n",
    "                \n",
    "                if int(company['org']['id']) in organizations_ids:\n",
    "                    continue\n",
    "                o = Organization()\n",
    "                o.id = int(company['org']['id'])\n",
    "                o.name = company['name']\n",
    "                o.name_primary = company['name_ex']['primary']\n",
    "                o.name_extension = company['name_ex']['extension'] if 'extension' in company['name_ex'] else ''\n",
    "                o.name_synonyms.append(o.name)\n",
    "                o.name_synonyms.append(o.name.lower())\n",
    "                o.name_synonyms.append(o.name_primary)\n",
    "                o.name_synonyms.append(o.name_primary.lower())\n",
    "                \n",
    "                if 'rubrics' in company.keys():\n",
    "                    o.main_rubrics['doublegis_rubrics_ids'] = np.unique(np.array([r['parent_id'] for r in company['rubrics']]))\n",
    "                    o.sub_rubrics['doublegis_rubrics_ids'] = np.unique(np.array([r['id'] for r in company['rubrics']]))\n",
    "\n",
    "                if 'contact_groups' in company.keys():\n",
    "                    contacts = [c for group in company['contact_groups'] for c in group['contacts']]\n",
    "                    o.contacts_json['email'] += [c['value'] for c in contacts if 'email' == c['type']]\n",
    "                    o.contacts_json['phone'] += [c['value'] for c in contacts if 'phone' == c['type']]\n",
    "                    o.contacts_json['other'] += [c['value'] for c in contacts if 'phone' != c['type'] and 'email' != c['type']]\n",
    "\n",
    "                organizations_ids.append(o.id)\n",
    "                new_organizations.append(o)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print('Error while company parse {0}. Data: {1}. Status code: {2}'.format(e, i, r.status_code))\n",
    "            \n",
    "    return new_filials, new_organizations\n",
    "            \n",
    "\n",
    "def update_filials_dates_parallel(workers, ids, verbose=False):\n",
    "    all_filials = []\n",
    "    all_organizations = []\n",
    "    \n",
    "    api = Api2Gis()\n",
    "    api.load()\n",
    "    filials_ids = list(map(lambda x: x.doublegis_id, api.filials))\n",
    "    organizations_ids = list(map(lambda x: x.id, api.organizations))\n",
    "    \n",
    "    pool = Pool(processes=workers)\n",
    "\n",
    "    chunk_size = len(ids) // workers\n",
    "    results = [pool.apply_async(update_filials_dates, (ids[chunk_size * i:chunk_size * (i + 1)],\n",
    "                                                       filials_ids,\n",
    "                                                       organizations_ids,\n",
    "                                                       verbose))\n",
    "               for i in range(workers)]\n",
    "\n",
    "    data = []\n",
    "    for async in results:\n",
    "        data.append(async.get())\n",
    "        \n",
    "    for fil, org in data:\n",
    "        all_filials += fil\n",
    "        all_organizations += org\n",
    "        \n",
    "    return np.unique(all_filials), np.unique(all_organizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1524,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('removed_organizations', 'rb') as f:\n",
    "    ids = np.load(f)\n",
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552839072078. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838614152. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838719768. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838667085. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552839886943. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838629986. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838554480. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552839012311. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838574221. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552839381819. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838787480. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838787836. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while company parse 'building_id'. Data: 5348552838531183. Status code: 410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1449,)\n(911,)\n"
     ]
    }
   ],
   "source": [
    "fil, org = update_filials_dates_parallel(15, ids)\n",
    "print(fil.shape)\n",
    "print(org.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filials before: 154624\nOrgs before: 103206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filials after: 156073\nOrgs after: 104117\n"
     ]
    }
   ],
   "source": [
    "api = Api2Gis()\n",
    "api.load()\n",
    "\n",
    "print('Filials before: {0}'.format(api.filials.shape[0]))\n",
    "print('Orgs before: {0}'.format(api.organizations.shape[0]))\n",
    "api.filials = np.unique(np.append(api.filials, fil))\n",
    "api.organizations = np.unique(np.append(api.organizations, org))\n",
    "print('Filials after: {0}'.format(api.filials.shape[0]))\n",
    "print('Orgs after: {0}'.format(api.organizations.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}